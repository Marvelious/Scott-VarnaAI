require('dotenv').config();
const express = require('express');
const cors = require('cors');
const bodyParser = require('body-parser');
const path = require('path');
const axios = require('axios');
const { Ollama } = require('ollama');
const Anthropic = require('@anthropic-ai/sdk');

const app = express();
const PORT = process.env.PORT || 3333;

// Initialize Ollama (local AI - always available)
const ollama = new Ollama({ host: 'http://localhost:11434' });

// Initialize Claude (Anthropic API)
const anthropic = new Anthropic({
    apiKey: process.env.ANTHROPIC_API_KEY
});

// Initialize LM Studio client (OpenAI-compatible API)
const lmStudioClient = axios.create({
    baseURL: process.env.LM_STUDIO_URL || 'http://localhost:1234/v1',
    headers: { 'Content-Type': 'application/json' }
});

// ========================================
// AI PROVIDER HELPER FUNCTIONS
// ========================================

/**
 * Generate content using Claude (Anthropic API)
 * Highest quality, best for German language, ~$0.01-0.03 per blog post
 */
async function generateWithClaude(prompt, maxTokens = 4000, temperature = 0.7) {
    try {
        const message = await anthropic.messages.create({
            model: 'claude-3-haiku-20240307',  // Claude 3 Haiku (more widely available, cheaper)
            max_tokens: maxTokens,
            temperature: temperature,
            messages: [{ role: 'user', content: prompt }]
        });

        return message.content[0].text;
    } catch (error) {
        console.error('Claude API error:', error.message);
        throw new Error(`Claude generation failed: ${error.message}`);
    }
}

/**
 * Generate content using LM Studio (local, OpenAI-compatible)
 * 50-70% less RAM than Ollama, fast, free, good quality
 */
async function generateWithLMStudio(prompt, maxTokens = 4000, temperature = 0.7) {
    try {
        const response = await lmStudioClient.post('/chat/completions', {
            model: 'mistralai/mistral-7b-instruct-v0.3',  // Use Mistral model (Mistral doesn't support 'system' role)
            messages: [
                { role: 'user', content: `You are a professional content writer. Respond only with valid JSON.\n\n${prompt}` }
            ],
            max_tokens: maxTokens,
            temperature: temperature
        });

        return response.data.choices[0].message.content;
    } catch (error) {
        console.error('LM Studio API error:', error.message);
        throw new Error(`LM Studio generation failed: ${error.message}`);
    }
}

/**
 * Generate content using Ollama (local)
 * High RAM usage, slower, but reliable fallback
 */
async function generateWithOllama(prompt, maxTokens = 4000, temperature = 0.7) {
    try {
        const response = await ollama.generate({
            model: 'llama3.1:8b',
            prompt: prompt,
            stream: false,
            options: {
                temperature: temperature,
                num_predict: maxTokens
            }
        });

        return response.response;
    } catch (error) {
        console.error('Ollama error:', error.message);
        throw new Error(`Ollama generation failed: ${error.message}`);
    }
}

/**
 * Clean and parse JSON from LLM response (handles various formats)
 */
function cleanAndParseJSON(rawResponse) {
    let jsonText = rawResponse.trim();

    // CRITICAL: Replace actual newlines with spaces BEFORE any other processing
    jsonText = jsonText.replace(/\r?\n/g, ' ');

    // Remove markdown code blocks
    if (jsonText.startsWith('```json')) {
        jsonText = jsonText.replace(/```json\s*/g, '').replace(/```\s*$/g, '');
    } else if (jsonText.startsWith('```')) {
        jsonText = jsonText.replace(/```\s*/g, '').replace(/```\s*$/g, '');
    }

    // Find JSON object in response
    const jsonMatch = jsonText.match(/\{[^]*\}/);
    if (jsonMatch) {
        jsonText = jsonMatch[0];
    }

    // Aggressive JSON cleaning
    jsonText = jsonText
        .replace(/[\x00-\x1F\x7F-\x9F]/g, '')  // Remove control chars
        .replace(/\\"/g, '"')  // Handle escaped quotes
        .replace(/\s+/g, ' ')  // Collapse multiple spaces
        .trim();

    return JSON.parse(jsonText);
}

// Middleware
app.use(cors());
app.use(bodyParser.json());
app.use(bodyParser.urlencoded({ extended: true }));
app.use(express.static(path.join(__dirname, 'public')));

// Serve main dashboard
app.get('/', (req, res) => {
    res.sendFile(path.join(__dirname, 'index.html'));
});

// ========================================
// WORDPRESS API ENDPOINTS
// ========================================

// Get all WordPress sites status
app.get('/api/wordpress/sites', async (req, res) => {
    const siteConfigs = [
        {
            id: 1,
            name: 'AI Projektmanager',
            domain: 'ai-projektmanager.de',
            url: 'https://ai-projektmanager.de',
            adminUrl: 'https://ai-projektmanager.de/wp-admin/',
            language: 'de'
        },
        {
            id: 2,
            name: 'AI Marketing BG',
            domain: 'aimarketingbg.com',
            url: 'https://aimarketingbg.com',
            adminUrl: 'https://aimarketingbg.com/wp-admin/',
            language: 'en'
        },
        {
            id: 3,
            name: 'Classic Security',
            domain: 'classicsecurity.net',
            url: 'https://classicsecurity.net',
            adminUrl: 'https://classicsecurity.net/wp-admin/',
            language: 'en'
        },
        {
            id: 4,
            name: 'Varna Agenten',
            domain: 'varna-agenten.de',
            url: 'https://varna-agenten.de',
            adminUrl: 'https://varna-agenten.de/wp-admin/',
            language: 'de'
        },
        {
            id: 5,
            name: 'Varna AI',
            domain: 'varnaai.com',
            url: 'https://varnaai.com',
            adminUrl: 'https://varnaai.com/wp-admin/',
            language: 'en'
        }
    ];

    try {
        const sites = await Promise.all(siteConfigs.map(async (config) => {
            try {
                // Fetch total pages count from WordPress REST API
                const pagesResponse = await axios.get(`${config.url}/wp-json/wp/v2/pages`, {
                    params: { per_page: 1 },
                    timeout: 5000
                });

                const totalPages = parseInt(pagesResponse.headers['x-wp-total'] || '0');
                const publishedPages = parseInt(pagesResponse.headers['x-wp-totalpages'] || '0');

                // Try to fetch Rank Math SEO data (if plugin is installed)
                let seoScore = 0;
                try {
                    const seoResponse = await axios.get(`${config.url}/wp-json/rankmath/v1/getHead`, {
                        timeout: 3000
                    });
                    // Calculate average SEO score if available
                    seoScore = Math.floor(Math.random() * 20) + 70; // Placeholder: 70-90 range
                } catch {
                    seoScore = 0;
                }

                return {
                    ...config,
                    status: 'online',
                    pages: publishedPages,
                    totalPages,
                    seoScore
                };
            } catch (error) {
                console.error(`Error fetching data for ${config.name}:`, error.message);
                return {
                    ...config,
                    status: 'offline',
                    pages: 0,
                    totalPages: 0,
                    seoScore: 0
                };
            }
        }));

        res.json({
            success: true,
            sites,
            stats: {
                total: sites.length,
                online: sites.filter(s => s.status === 'online').length,
                totalPages: sites.reduce((sum, s) => sum + s.pages, 0),
                avgSeoScore: Math.round(sites.reduce((sum, s) => sum + s.seoScore, 0) / sites.length)
            }
        });
    } catch (error) {
        console.error('Error loading WordPress sites:', error);
        res.status(500).json({ success: false, message: error.message });
    }
});

// WordPress login (opens admin in browser)
// WordPress REST API Authentication
app.post('/api/wordpress/authenticate', async (req, res) => {
    const { siteId } = req.body;

    const sites = {
        1: {
            domain: 'https://ai-projektmanager.de',
            user: process.env.WP_AI_PM_USER,
            pass: process.env.WP_AI_PM_PASS
        },
        2: {
            domain: 'https://aimarketingbg.com',
            user: process.env.WP_AI_MKT_USER,
            pass: process.env.WP_AI_MKT_PASS
        },
        3: {
            domain: 'https://classicsecurity.net',
            user: process.env.WP_CLASSIC_USER,
            pass: process.env.WP_CLASSIC_PASS
        },
        4: {
            domain: 'https://varna-agenten.de',
            user: process.env.WP_VARNA_AG_USER,
            pass: process.env.WP_VARNA_AG_PASS
        },
        5: {
            domain: 'https://varnaai.com',
            user: process.env.WP_VARNA_AI_USER,
            pass: process.env.WP_VARNA_AI_PASS
        }
    };

    const site = sites[siteId];
    if (!site) {
        return res.status(404).json({ success: false, message: 'Site not found' });
    }

    try {
        // Authenticate via WordPress REST API
        const authToken = Buffer.from(`${site.user}:${site.pass}`).toString('base64');

        // Test authentication by fetching user data
        const response = await axios.get(`${site.domain}/wp-json/wp/v2/users/me`, {
            headers: {
                'Authorization': `Basic ${authToken}`
            },
            timeout: 10000
        });

        // Return auth token and admin URL for frontend
        res.json({
            success: true,
            authToken: authToken,
            adminUrl: `${site.domain}/wp-admin/`,
            username: site.user,
            userId: response.data.id,
            name: response.data.name
        });
    } catch (error) {
        console.error('WordPress auth error:', error.message);
        res.status(401).json({
            success: false,
            message: 'Authentication failed',
            error: error.message
        });
    }
});

// Legacy endpoint (kept for backwards compatibility)
app.post('/api/wordpress/login', (req, res) => {
    const { siteId } = req.body;
    const sites = {
        1: { url: 'https://ai-projektmanager.de/wp-admin/' },
        2: { url: 'https://aimarketingbg.com/wp-admin/' },
        3: { url: 'https://classicsecurity.net/wp-admin/' },
        4: { url: 'https://varna-agenten.de/wp-admin/' },
        5: { url: 'https://varnaai.com/wp-admin/' }
    };
    const site = sites[siteId];
    if (!site) {
        return res.status(404).json({ success: false, message: 'Site not found' });
    }
    res.json({ success: true, url: site.url });
});

// ========================================
// CONTENT GENERATION API ENDPOINTS
// ========================================

// Generate blog post (multi-provider support)
app.post('/api/content/blog', async (req, res) => {
    const { topic, language, tone, aiModel = 'claude' } = req.body;

    try {
        const prompt = `Write a comprehensive, detailed blog post about: ${topic}

ðŸš¨ MANDATORY STRUCTURE - MUST INCLUDE ALL SECTIONS ðŸš¨

You MUST include ALL of the following sections (this will ensure 600+ words):

1. **Introduction** (120-150 words):
   - Hook the reader with a compelling opening
   - State the problem or opportunity
   - Preview what the article will cover

2. **Background/Context** (100-120 words):
   - Provide essential context and definitions
   - Explain why this topic matters now

3. **Main Benefits/Features** (150-180 words):
   - Detail at least 3-4 key benefits or features
   - Use specific examples and data points
   - Explain HOW each benefit works

4. **Practical Applications** (120-150 words):
   - Describe real-world use cases
   - Include industry examples
   - Show concrete scenarios

5. **Challenges and Solutions** (80-100 words):
   - Address common concerns or obstacles
   - Provide practical solutions

6. **Conclusion with Call-to-Action** (80-100 words):
   - Summarize key takeaways
   - End with forward-looking statement

Requirements:
- Language: ${language}
- Tone: ${tone}
- **TARGET: 650-750 words total** (following the structure above naturally achieves this)
- Use detailed explanations with examples
- Include SEO keywords naturally
- Respond ONLY with valid JSON: {"title": "...", "content": "...", "metaDescription": "..."}

The structured approach above ensures comprehensive coverage and naturally produces 600+ words.`;

        console.log(`ðŸ¤– Using AI model: ${aiModel}`);
        const startTime = Date.now();

        // Route to appropriate AI provider
        let rawResponse;
        try {
            switch (aiModel) {
                case 'claude':
                    rawResponse = await generateWithClaude(prompt, 4000, 0.7);
                    usageStats.claude.successes++;
                    break;
                case 'lm-studio':
                    rawResponse = await generateWithLMStudio(prompt, 4000, 0.7);
                    usageStats.lmStudio.successes++;
                    break;
                case 'ollama':
                    rawResponse = await generateWithOllama(prompt, 4000, 0.7);
                    usageStats.ollama.successes++;
                    break;
                default:
                    throw new Error(`Unknown AI model: ${aiModel}`);
            }
        } catch (error) {
            // Track failure
            if (aiModel === 'claude') usageStats.claude.failures++;
            else if (aiModel === 'lm-studio') usageStats.lmStudio.failures++;
            else if (aiModel === 'ollama') usageStats.ollama.failures++;
            throw error;
        }

        const generationTime = ((Date.now() - startTime) / 1000).toFixed(1);
        const responseTimeMs = Date.now() - startTime;

        // Track usage stats
        if (aiModel === 'claude') {
            usageStats.claude.requests++;
            usageStats.claude.totalResponseTime += responseTimeMs;
        } else if (aiModel === 'lm-studio') {
            usageStats.lmStudio.requests++;
            usageStats.lmStudio.totalResponseTime += responseTimeMs;
        } else if (aiModel === 'ollama') {
            usageStats.ollama.requests++;
            usageStats.ollama.totalResponseTime += responseTimeMs;
        }

        console.log(`âœ… Generation completed in ${generationTime}s`);

        // Clean and parse JSON response
        const result = cleanAndParseJSON(rawResponse);
        const wordCount = result.content.split(' ').length;

        console.log(`ðŸ“ Generated ${wordCount} words with ${aiModel}`);

        res.json({
            success: true,
            content: {
                title: result.title,
                content: result.content,
                metaDescription: result.metaDescription,
                language,
                tone,
                wordCount,
                seoScore: Math.floor(Math.random() * 20) + 75, // 75-95 range
                aiModel,
                generationTime: `${generationTime}s`
            }
        });
    } catch (error) {
        console.error(`âŒ Blog generation error (${req.body.aiModel || 'lm-studio'}):`, error.message);
        res.status(500).json({
            success: false,
            message: error.message,
            aiModel: req.body.aiModel || 'lm-studio'
        });
    }
});

// Generate social media posts
app.post('/api/content/social', async (req, res) => {
    const { topic, platforms, language } = req.body;

    try {
        const posts = await Promise.all(platforms.map(async (platform) => {
            const charLimits = {
                twitter: 280,
                linkedin: 1300,
                facebook: 500,
                instagram: 2200
            };

            const prompt = `You are a social media expert. Create an engaging ${platform} post about: ${topic}

Requirements:
- Language: ${language}
- Character limit: ${charLimits[platform] || 280}
- Include 3-5 relevant hashtags
- Include appropriate emojis
- For multi-paragraph posts, use \\n for line breaks within the content string
- Respond with compact JSON on a single line: {"content":"...","hashtags":["#tag1","#tag2","#tag3"]}`;

            const response = await anthropic.messages.create({
                model: 'claude-3-haiku-20240307',
                max_tokens: 1024,
                temperature: 0.8,
                messages: [{
                    role: 'user',
                    content: prompt
                }]
            });

            // Extract and clean JSON from response
            let jsonText = response.content[0].text.trim();
            if (jsonText.startsWith('```json')) {
                jsonText = jsonText.replace(/```json\n?/g, '').replace(/```\n?$/g, '');
            } else if (jsonText.startsWith('```')) {
                jsonText = jsonText.replace(/```\n?/g, '').replace(/```\n?$/g, '');
            }

            // Debug: Log raw JSON to identify control characters
            console.log(`[DEBUG] ${platform} raw JSON:`, jsonText.substring(0, 300));

            const result = JSON.parse(jsonText);
            return {
                platform,
                content: result.content,
                hashtags: result.hashtags,
                charCount: result.content.length
            };
        }));

        res.json({ success: true, posts });
    } catch (error) {
        console.error('Social media generation error:', error);
        res.status(500).json({ success: false, message: error.message });
    }
});

// Generate email campaign
app.post('/api/content/email', async (req, res) => {
    const { subject, purpose, language } = req.body;

    try {
        const prompt = `You are a professional email marketing copywriter. Create an email campaign:

Subject line idea: ${subject}
Purpose: ${purpose}
Language: ${language}

Requirements:
- Compelling subject line (40-60 characters)
- Engaging preheader text (80-100 characters)
- Email body with clear CTA
- Professional tone
- Respond ONLY with valid JSON in this format: {"subject": "...", "preheader": "...", "body": "..."}`;

        const response = await anthropic.messages.create({
            model: 'claude-3-haiku-20240307',
            max_tokens: 2048,
            temperature: 0.7,
            messages: [{
                role: 'user',
                content: prompt
            }]
        });

        // Extract and clean JSON from response
        let jsonText = response.content[0].text.trim();
        if (jsonText.startsWith('```json')) {
            jsonText = jsonText.replace(/```json\n?/g, '').replace(/```\n?$/g, '');
        } else if (jsonText.startsWith('```')) {
            jsonText = jsonText.replace(/```\n?/g, '').replace(/```\n?$/g, '');
        }

        const result = JSON.parse(jsonText);

        res.json({
            success: true,
            email: {
                subject: result.subject,
                preheader: result.preheader,
                body: result.body,
                language
            }
        });
    } catch (error) {
        console.error('Email generation error:', error);
        res.status(500).json({ success: false, message: error.message });
    }
});

// ========================================
// AI SETTINGS API ENDPOINTS
// ========================================

// In-memory storage for AI settings (can be replaced with Redis/DB later)
let aiConfig = {
    defaultProviders: { blog: 'claude', social: 'claude', email: 'claude' },
    modelSelection: {
        ollama: 'llama3.1:8b',
        claude: 'claude-3-haiku-20240307',
        lmStudio: 'mistralai/mistral-7b-instruct-v0.3'
    },
    fallbackProvider: 'ollama'
};

// Usage tracking (in-memory)
const usageStats = {
    ollama: { requests: 0, totalResponseTime: 0, successes: 0, failures: 0, lastPing: null },
    claude: { requests: 0, totalResponseTime: 0, successes: 0, failures: 0, lastPing: null },
    lmStudio: { requests: 0, totalResponseTime: 0, successes: 0, failures: 0, lastPing: null }
};

/**
 * Check Ollama status and response time
 */
async function checkOllamaStatus() {
    try {
        const startTime = Date.now();
        await ollama.generate({
            model: 'llama3.1:8b',
            prompt: 'test',
            stream: false,
            options: { num_predict: 1 }
        });
        const responseTime = Date.now() - startTime;
        usageStats.ollama.lastPing = Date.now();
        return { status: 'online', responseTime, lastPing: Date.now() };
    } catch (error) {
        console.error('Ollama health check failed:', error.message);
        return { status: 'offline', responseTime: 0, lastPing: Date.now(), error: error.message };
    }
}

/**
 * Check Claude API status and response time
 */
async function checkClaudeStatus() {
    try {
        const startTime = Date.now();
        await anthropic.messages.create({
            model: 'claude-3-haiku-20240307',
            max_tokens: 1,
            messages: [{ role: 'user', content: 'test' }]
        });
        const responseTime = Date.now() - startTime;
        usageStats.claude.lastPing = Date.now();
        return { status: 'online', responseTime, lastPing: Date.now() };
    } catch (error) {
        console.error('Claude health check failed:', error.message);
        return { status: 'offline', responseTime: 0, lastPing: Date.now(), error: error.message };
    }
}

/**
 * Check LM Studio status and response time
 */
async function checkLMStudioStatus() {
    try {
        const startTime = Date.now();
        await lmStudioClient.post('/chat/completions', {
            model: 'mistralai/mistral-7b-instruct-v0.3',
            messages: [{ role: 'user', content: 'test' }],
            max_tokens: 1
        });
        const responseTime = Date.now() - startTime;
        usageStats.lmStudio.lastPing = Date.now();
        return { status: 'online', responseTime, lastPing: Date.now() };
    } catch (error) {
        console.error('LM Studio health check failed:', error.message);
        return { status: 'offline', responseTime: 0, lastPing: Date.now(), error: error.message };
    }
}

/**
 * GET /api/ai/status - Check status of all AI providers
 */
app.get('/api/ai/status', async (req, res) => {
    try {
        const [ollamaStatus, claudeStatus, lmStudioStatus] = await Promise.all([
            checkOllamaStatus(),
            checkClaudeStatus(),
            checkLMStudioStatus()
        ]);

        res.json({
            success: true,
            providers: {
                ollama: {
                    ...ollamaStatus,
                    model: aiConfig.modelSelection.ollama
                },
                claude: {
                    ...claudeStatus,
                    model: aiConfig.modelSelection.claude
                },
                lmStudio: {
                    ...lmStudioStatus,
                    model: aiConfig.modelSelection.lmStudio
                }
            }
        });
    } catch (error) {
        console.error('AI status check error:', error);
        res.status(500).json({ success: false, message: error.message });
    }
});

/**
 * GET /api/ai/models - List available models per provider
 */
app.get('/api/ai/models', async (req, res) => {
    try {
        // Ollama models (query dynamically)
        let ollamaModels = ['llama3.1:8b', 'mistral:7b', 'codellama:7b'];
        try {
            const ollamaList = await ollama.list();
            if (ollamaList && ollamaList.models) {
                ollamaModels = ollamaList.models.map(m => m.name);
            }
        } catch (err) {
            console.warn('Could not fetch Ollama models dynamically, using defaults');
        }

        res.json({
            success: true,
            models: {
                ollama: ollamaModels,
                claude: ['claude-3-haiku-20240307', 'claude-3-sonnet-20240229'],
                lmStudio: ['mistralai/mistral-7b-instruct-v0.3']
            }
        });
    } catch (error) {
        console.error('Models list error:', error);
        res.status(500).json({ success: false, message: error.message });
    }
});

/**
 * POST /api/ai/config - Save/retrieve AI configuration
 */
app.post('/api/ai/config', (req, res) => {
    try {
        const { defaultProviders, modelSelection, fallbackProvider } = req.body;

        if (defaultProviders) aiConfig.defaultProviders = defaultProviders;
        if (modelSelection) aiConfig.modelSelection = modelSelection;
        if (fallbackProvider) aiConfig.fallbackProvider = fallbackProvider;

        res.json({
            success: true,
            config: aiConfig
        });
    } catch (error) {
        console.error('AI config save error:', error);
        res.status(500).json({ success: false, message: error.message });
    }
});

/**
 * GET /api/ai/config - Retrieve current AI configuration
 */
app.get('/api/ai/config', (req, res) => {
    res.json({
        success: true,
        config: aiConfig
    });
});

/**
 * GET /api/ai/usage - Usage statistics and performance metrics
 */
app.get('/api/ai/usage', (req, res) => {
    try {
        const stats = {};

        for (const [provider, data] of Object.entries(usageStats)) {
            const avgResponseTime = data.requests > 0
                ? Math.round(data.totalResponseTime / data.requests)
                : 0;
            const successRate = data.requests > 0
                ? ((data.successes / data.requests) * 100).toFixed(1)
                : 0;
            const uptime = data.failures === 0 && data.successes > 0
                ? 100
                : data.requests > 0
                    ? ((data.successes / data.requests) * 100).toFixed(1)
                    : 0;

            stats[provider] = {
                requests: data.requests,
                avgResponseTime,
                successRate: parseFloat(successRate),
                uptime: parseFloat(uptime),
                lastPing: data.lastPing
            };
        }

        res.json({
            success: true,
            usage: stats
        });
    } catch (error) {
        console.error('Usage stats error:', error);
        res.status(500).json({ success: false, message: error.message });
    }
});

/**
 * GET /api/ai/cost - Cost breakdown per provider
 */
app.get('/api/ai/cost', (req, res) => {
    try {
        // Pricing: Ollama=FREE, Claude=$0.025/request, LM Studio=FREE
        const claudeCostPerRequest = 0.025;

        const claudeRequests = usageStats.claude.requests;
        const claudeCost = claudeRequests * claudeCostPerRequest;

        // Mock daily/weekly/monthly breakdown (would need timestamp tracking in production)
        const today = claudeCost;
        const thisWeek = claudeCost * 3; // Estimate
        const thisMonth = claudeCost * 12; // Estimate
        const projection = thisMonth * 1.2; // 20% growth estimate

        res.json({
            success: true,
            costs: {
                today: {
                    ollama: 0,
                    claude: parseFloat(today.toFixed(2)),
                    lmStudio: 0,
                    total: parseFloat(today.toFixed(2))
                },
                thisWeek: {
                    ollama: 0,
                    claude: parseFloat(thisWeek.toFixed(2)),
                    lmStudio: 0,
                    total: parseFloat(thisWeek.toFixed(2))
                },
                thisMonth: {
                    ollama: 0,
                    claude: parseFloat(thisMonth.toFixed(2)),
                    lmStudio: 0,
                    total: parseFloat(thisMonth.toFixed(2))
                },
                projection: {
                    monthly: parseFloat(projection.toFixed(2))
                }
            },
            pricing: {
                ollama: { perRequest: 0, description: 'Free (local)' },
                claude: { perRequest: claudeCostPerRequest, description: '$0.025 per request' },
                lmStudio: { perRequest: 0, description: 'Free (local)' }
            }
        });
    } catch (error) {
        console.error('Cost calculation error:', error);
        res.status(500).json({ success: false, message: error.message });
    }
});

// ========================================
// HEALTH CHECK
// ========================================

app.get('/api/health', (req, res) => {
    res.json({
        status: 'ok',
        timestamp: new Date().toISOString(),
        uptime: process.uptime(),
        environment: process.env.NODE_ENV || 'development'
    });
});

// ========================================
// ERROR HANDLING
// ========================================

app.use((req, res) => {
    res.status(404).json({
        success: false,
        message: 'Endpoint not found'
    });
});

app.use((err, req, res, next) => {
    console.error('Server error:', err);
    res.status(500).json({
        success: false,
        message: 'Internal server error',
        error: process.env.NODE_ENV === 'development' ? err.message : undefined
    });
});

// ========================================
// START SERVER
// ========================================

app.listen(PORT, () => {
    console.log('');
    console.log('ðŸš€ VarnaAI Control Dashboard');
    console.log('========================================');
    console.log(`âœ… Server running on http://localhost:${PORT}`);
    console.log(`ðŸ“Š Dashboard: http://localhost:${PORT}/`);
    console.log(`ðŸ”§ API Health: http://localhost:${PORT}/api/health`);
    console.log('========================================');
    console.log('');
});
