# Product Requirements Document: AI Settings Page Enhancement

## Project Overview
Update the AI Settings page in the VarnaAI Control Dashboard to provide comprehensive configuration and management for all three AI providers (Ollama, Claude, LM Studio) with real-time status monitoring, model selection, and cost tracking.

## Background
The current AI Settings tab exists but needs enhancement to provide:
- Real-time AI provider status (online/offline)
- Model selection and configuration
- API key management (masked display)
- Cost tracking and usage statistics
- Provider performance metrics
- Easy switching between providers

## User Stories

### 1. AI Provider Status Monitoring
**As a** dashboard user
**I want to** see the real-time status of all AI providers
**So that** I know which providers are available for content generation

**Acceptance Criteria:**
- Display online/offline status for Ollama, Claude, and LM Studio
- Show green indicator for online, red for offline, yellow for degraded
- Auto-refresh status every 30 seconds
- Display last successful ping timestamp

### 2. Model Configuration
**As a** dashboard user
**I want to** select and configure AI models for each provider
**So that** I can optimize quality vs. cost for different content types

**Acceptance Criteria:**
- Dropdown model selection for each provider
- Ollama: llama3.1:8b, mistral:7b, codellama:7b
- Claude: claude-3-haiku-20240307, claude-3-sonnet-20240229
- LM Studio: mistralai/mistral-7b-instruct-v0.3, other local models
- Save model preferences to browser localStorage
- Display model details (size, speed, quality rating)

### 3. API Key Management
**As a** dashboard user
**I want to** view and update API keys securely
**So that** I can manage authentication without exposing sensitive data

**Acceptance Criteria:**
- Display masked API keys (sk-ant-***...last4chars)
- "Show/Hide" toggle button for each key
- "Update Key" button to change API keys
- Never log or transmit keys in plain text
- Validate API key format before saving

### 4. Cost Tracking Dashboard
**As a** dashboard user
**I want to** track AI usage costs across all providers
**So that** I can monitor spending and optimize budget

**Acceptance Criteria:**
- Display total cost per provider (today, this week, this month)
- Show request count and average cost per request
- Cost breakdown by content type (blog, social, email)
- Estimated monthly cost projection based on usage trends
- Cost comparison chart (Claude vs Ollama vs LM Studio)

### 5. Provider Performance Metrics
**As a** dashboard user
**I want to** see performance metrics for each AI provider
**So that** I can choose the best provider for each task

**Acceptance Criteria:**
- Average response time (milliseconds)
- Success rate percentage
- Content quality rating (user feedback score)
- Uptime percentage (last 7 days)
- Performance comparison chart

### 6. Default Provider Selection
**As a** dashboard user
**I want to** set default AI providers for different content types
**So that** content generation uses my preferred providers automatically

**Acceptance Criteria:**
- Default provider for blog posts
- Default provider for social media
- Default provider for email campaigns
- Fallback provider if default is offline
- Save preferences to browser localStorage

## Technical Requirements

### API Endpoints Needed
```javascript
GET  /api/ai/status              // Check status of all providers
GET  /api/ai/models              // List available models per provider
POST /api/ai/config              // Update AI configuration
GET  /api/ai/usage               // Get usage statistics
GET  /api/ai/cost                // Get cost breakdown
```

### Server.js Modifications
1. Add health check functions for each AI provider
2. Track request counts and response times
3. Calculate costs based on provider pricing
4. Store usage data (in-memory or Redis for persistence)
5. Implement model switching logic

### Frontend Components
1. **Provider Status Cards** (3 cards for Ollama, Claude, LM Studio)
   - Status indicator (green/red/yellow dot)
   - Provider name and logo
   - Current model selected
   - Last ping timestamp
   - Quick actions (Test Connection, View Logs)

2. **Model Selection Panel**
   - Dropdown for each provider
   - Model details (description, size, speed rating)
   - "Set as Default" checkbox
   - Save/Cancel buttons

3. **API Key Management Panel**
   - Masked key display (sk-ant-***...xyz)
   - Show/Hide toggle
   - Update Key button with modal
   - Key validation status

4. **Cost Tracking Dashboard**
   - Total cost cards (today, week, month)
   - Request count chart (line chart)
   - Cost breakdown pie chart (by provider)
   - Monthly projection estimate

5. **Performance Metrics Panel**
   - Response time chart (bar chart)
   - Success rate percentage
   - Uptime status (7-day trend)
   - Quality rating (star rating)

### Design System (Blue & Gold Theme)
```css
colors: {
  'primary': '#2563eb',        // Royal blue
  'gold': '#f59e0b',           // Gold accent
  'success': '#10b981',        // Green (online)
  'alert': '#ef4444',          // Red (offline)
  'warning': '#f59e0b',        // Yellow (degraded)
  'dark-bg': '#0a0e1a',        // Deep navy
  'card-dark': '#1e293b',      // Slate
}
```

### Data Persistence
- **Browser localStorage**: Model preferences, default providers, UI settings
- **Server-side (in-memory)**: Usage statistics, cost tracking (reset on restart)
- **Future enhancement**: Redis for persistent usage data across restarts

## Success Metrics
1. **Provider Status Visibility**: Users can instantly see which AI providers are online
2. **Configuration Ease**: Users can switch models in < 30 seconds
3. **Cost Transparency**: Users can view accurate cost breakdown per provider
4. **Performance Insights**: Users can identify fastest/most reliable provider
5. **Default Automation**: 80%+ of content generation uses default providers without manual selection

## Implementation Phases

### Phase 1: Provider Status Monitoring (MVP)
- Add health check endpoints
- Display status cards for all 3 providers
- Auto-refresh status every 30 seconds
- Show last successful ping

### Phase 2: Model Configuration
- Add model selection dropdowns
- Implement model switching logic in server.js
- Save preferences to localStorage
- Display model details

### Phase 3: API Key Management
- Add masked key display
- Implement show/hide toggle
- Add update key modal
- Validate key format

### Phase 4: Cost Tracking
- Track request counts per provider
- Calculate costs based on pricing
- Display cost breakdown charts
- Add monthly projection

### Phase 5: Performance Metrics
- Track response times
- Calculate success rates
- Display uptime percentages
- Add performance comparison chart

## Out of Scope (Future Enhancements)
- Custom model training
- AI prompt template management
- A/B testing for content quality
- Provider auto-failover
- Advanced analytics (sentiment analysis, engagement prediction)

## Dependencies
- Express.js server with AI provider clients initialized
- AlpineJS for reactive UI
- Chart.js or similar for data visualization
- Tailwind CSS for styling

## Timeline Estimate
- Phase 1 (Status Monitoring): 2-3 hours
- Phase 2 (Model Configuration): 2-3 hours
- Phase 3 (API Key Management): 1-2 hours
- Phase 4 (Cost Tracking): 3-4 hours
- Phase 5 (Performance Metrics): 2-3 hours

**Total Estimated Time**: 10-15 hours of development

## Notes
- Prioritize Phase 1 (Status Monitoring) as foundation
- Phases 2-3 can be developed in parallel
- Phases 4-5 require data collection from server.js modifications
- All phases should maintain blue & gold color theme consistency
